{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1188, 832)\n",
      "(776, 832)\n",
      "(1964, 832)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from fancyimpute import simple_fill\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# To use this experimental feature, we need to explicitly ask for it:\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "\"\"\"\n",
    "0. median imputation\n",
    "1. normalise\n",
    "# OUTLIER DETECTION?\n",
    "2. feature selection using rfe to 250 ( -> IMPROVE!!!)\n",
    "3. grad, knn regressors -> bagging -> average (1, 0.5)\n",
    "4. => final prediction\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "### 0. import -> impute\n",
    "#X_in = np.genfromtxt ('X_train.csv', delimiter=\",\")[1:,1:]\n",
    "X_in = np.genfromtxt ('Xtrain_clean.csv', delimiter=\",\")[1:,2:]\n",
    "y_in = np.genfromtxt ('Xtrain_clean.csv', delimiter=\",\")[1:,1]\n",
    "#X_in = np.delete(X_in,1,1)\n",
    "#y_in = np.genfromtxt ('y_train.csv', delimiter=\",\")[1:,1:]\n",
    "#X_out = np.genfromtxt ('X_test.csv', delimiter=\",\")[1:,1:] #also contains NAs\n",
    "X_out = np.genfromtxt ('Xtest_clean.csv', delimiter=\",\")[1:,1:] #also contains NAs\n",
    "print(X_in.shape)\n",
    "print(X_out.shape)\n",
    "labels_out = np.genfromtxt ('Xtest_clean.csv', delimiter=\",\")[1:,0]\n",
    "print(X_tot.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tot = np.concatenate((X_in, X_out), axis=0)\n",
    "#median_imputer = simple_fill.SimpleFill(fill_method=\"median\")\n",
    "X_medimp = median_imputer.fit_transform(X_tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "N_SPLITS = 5\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "X_full = np.concatenate((X_in, X_out), axis=0)\n",
    "y_full = y_in\n",
    "n_samples, n_features = np.shape(X_full)\n",
    "\n",
    "X_missing = X_full\n",
    "y_missing = y_in\n",
    "# Estimate the score after iterative imputation of the missing values\n",
    "# with different estimators\n",
    "estimators = [\n",
    "    BayesianRidge(),\n",
    "]\n",
    "br_estimator = BayesianRidge()\n",
    "\n",
    "imputer = IterativeImputer(random_state=0, estimator=br_estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imp = imputer.fit_transform(X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"X_imp.csv\", X_imp, delimiter=\",\", header=\"id,y\", comments=\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1964, 832)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(776, 832)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1188, 832)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(X_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt_imp = imputer.transform(X_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"Xt_imp.csv\", Xt_imp, delimiter=\",\", header=\"id,y\", comments=\"\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_id = 4\n",
    "#plt.hist(X_imp[:,feat_id],20)\n",
    "#plt.hist(X_medimp[:,feat_id],20)\n",
    "#plt.hist(Xt_imp[:,feat_id],20)\n",
    "X_in_imp = X_imp[:X_in.shape[0],:]\n",
    "X_out_imp = X_imp[X_in.shape[0]:,:]\n",
    "#plt.hist(X_in_imp[:,feat_id],20)\n",
    "#plt.hist(X_out_imp[:,feat_id],20)\n",
    "plt.hist(X_in[:,feat_id],20)\n",
    "plt.hist(X_out[:,feat_id],20)\n",
    "plt.hist(X_out_imp[:,feat_id],20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(Xt_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1188, 832)\n",
      "(776, 832)\n"
     ]
    }
   ],
   "source": [
    "### 1. normalise\n",
    "\n",
    "#X_in = X_imp;\n",
    "#X_out = Xt_imp;\n",
    "X_tot = X_imp\n",
    "#X_tot = np.concatenate((X_in, X_out), axis=0)\n",
    "scaler = StandardScaler()\n",
    "X_tot = scaler.fit_transform(X_tot)\n",
    "X_in = X_tot[:X_in.shape[0],:]\n",
    "X_out = X_tot[X_in.shape[0]:,:]\n",
    "print(X_in.shape)\n",
    "print(X_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 832 features.\n",
      "Fitting estimator with 812 features.\n",
      "Fitting estimator with 792 features.\n",
      "Fitting estimator with 772 features.\n",
      "Fitting estimator with 752 features.\n",
      "Fitting estimator with 732 features.\n",
      "Fitting estimator with 712 features.\n",
      "Fitting estimator with 692 features.\n",
      "Fitting estimator with 672 features.\n",
      "Fitting estimator with 652 features.\n",
      "Fitting estimator with 632 features.\n",
      "Fitting estimator with 612 features.\n",
      "Fitting estimator with 592 features.\n",
      "Fitting estimator with 572 features.\n",
      "Fitting estimator with 552 features.\n",
      "Fitting estimator with 532 features.\n",
      "Fitting estimator with 512 features.\n",
      "Fitting estimator with 492 features.\n",
      "Fitting estimator with 472 features.\n",
      "Fitting estimator with 452 features.\n",
      "Fitting estimator with 432 features.\n",
      "Fitting estimator with 412 features.\n",
      "Fitting estimator with 392 features.\n",
      "Fitting estimator with 372 features.\n",
      "Fitting estimator with 352 features.\n",
      "Fitting estimator with 332 features.\n",
      "Fitting estimator with 312 features.\n",
      "Fitting estimator with 300 features.\n",
      "Fitting estimator with 297 features.\n",
      "Fitting estimator with 294 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 288 features.\n",
      "Fitting estimator with 285 features.\n",
      "Fitting estimator with 282 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 273 features.\n",
      "Fitting estimator with 270 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 264 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 258 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 252 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 240 features.\n",
      "Fitting estimator with 237 features.\n",
      "Fitting estimator with 234 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 228 features.\n",
      "Fitting estimator with 225 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 210 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 204 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 200 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 198 features.\n",
      "Fitting estimator with 197 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 194 features.\n",
      "Fitting estimator with 193 features.\n",
      "Fitting estimator with 192 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 190 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 188 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 185 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 182 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 180 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 177 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 170 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 165 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 162 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "0.9996853882145429\n"
     ]
    }
   ],
   "source": [
    "### 2. feature selection\n",
    "estimator = GradientBoostingRegressor(loss=\"ls\", n_estimators=500, max_depth=4, subsample=0.7, random_state=666, max_features=\"auto\")\n",
    "rfe = RFE(estimator, n_features_to_select=300, step=20, verbose=1)\n",
    "rfe.fit_transform(X_in, y_in)\n",
    "indx = rfe.get_support(indices=True)\n",
    "X_in = X_in[:,indx]\n",
    "X_out = X_out[:,indx]\n",
    "\n",
    "rfe = RFE(estimator, n_features_to_select=200, step=3, verbose=1)\n",
    "rfe.fit_transform(X_in, y_in)\n",
    "indx = rfe.get_support(indices=True)\n",
    "X_in = X_in[:,indx]\n",
    "X_out = X_out[:,indx]\n",
    "\n",
    "rfe = RFE(estimator, n_features_to_select=150, step=1, verbose=1)\n",
    "rfe.fit_transform(X_in, y_in)\n",
    "indx = rfe.get_support(indices=True)\n",
    "X_in = X_in[:,indx]\n",
    "X_out = X_out[:,indx]\n",
    "\n",
    "\n",
    "\n",
    "### 3. use different regressors\n",
    "grad_1 = GradientBoostingRegressor(n_estimators=500, max_depth=4, subsample=0.8, random_state=666, max_features=\"auto\")\n",
    "grad_2 = GradientBoostingRegressor(n_estimators=500, max_depth=4, subsample=0.8, random_state=667, max_features=\"auto\")\n",
    "grad_3 = GradientBoostingRegressor(n_estimators=500, max_depth=4, subsample=0.8, random_state=668, max_features=\"auto\")\n",
    "grad_4 = GradientBoostingRegressor(n_estimators=500, max_depth=4, subsample=0.8, random_state=669, max_features=\"auto\")\n",
    "grad_5 = GradientBoostingRegressor(n_estimators=500, max_depth=4, subsample=0.8, random_state=670, max_features=\"auto\")\n",
    "\n",
    "grad_6 = GradientBoostingRegressor(loss=\"ls\", n_estimators=500, max_depth=4, subsample=0.7, random_state=671, max_features=\"auto\")\n",
    "grad_7 = GradientBoostingRegressor(loss=\"ls\", n_estimators=500, max_depth=4, subsample=0.7, random_state=672, max_features=\"auto\")\n",
    "grad_8 = GradientBoostingRegressor(loss=\"ls\", n_estimators=500, max_depth=4, subsample=0.7, random_state=673, max_features=\"auto\")\n",
    "grad_9 = GradientBoostingRegressor(loss=\"ls\", n_estimators=500, max_depth=4, subsample=0.7, random_state=674, max_features=\"auto\")\n",
    "grad_10 = GradientBoostingRegressor(loss=\"ls\", n_estimators=500, max_depth=4, subsample=0.7, random_state=675, max_features=\"auto\")\n",
    "\n",
    "grad_11 = GradientBoostingRegressor(loss=\"huber\", n_estimators=500, max_depth=4, subsample=0.7, random_state=676, max_features=\"auto\")\n",
    "grad_12 = GradientBoostingRegressor(loss=\"huber\", n_estimators=500, max_depth=4, subsample=0.7, random_state=677, max_features=\"auto\")\n",
    "grad_13 = GradientBoostingRegressor(loss=\"huber\", n_estimators=500, max_depth=4, subsample=0.7, random_state=678, max_features=\"auto\")\n",
    "grad_14 = GradientBoostingRegressor(loss=\"huber\", n_estimators=500, max_depth=4, subsample=0.7, random_state=679, max_features=\"auto\")\n",
    "grad_15 = GradientBoostingRegressor(loss=\"huber\", n_estimators=500, max_depth=4, subsample=0.7, random_state=680, max_features=\"auto\")\n",
    "\n",
    "\n",
    "regs = [grad_1, grad_2, grad_3, grad_4, grad_5, grad_6, grad_7, grad_8, grad_9, grad_10,\n",
    "        grad_11, grad_12, grad_13, grad_14, grad_15]\n",
    "fits= np.zeros((X_in.shape[0], len(regs)))\n",
    "preds = np.zeros((X_out.shape[0], len(regs)))\n",
    "for i, reg in enumerate(regs):\n",
    "    reg.fit(X_in, np.ravel(y_in))\n",
    "    fits[:, i] = reg.predict(X_in)\n",
    "    preds[:, i] = reg.predict(X_out)\n",
    "\n",
    "\n",
    "train_pred = np.mean(fits, axis=1)\n",
    "test_pred = np.mean(preds, axis=1)\n",
    "\n",
    "print(r2_score(y_in, np.ravel(train_pred))) # training accuracy\n",
    "\n",
    "test_pred = np.reshape(test_pred, (test_pred.shape[0],1))\n",
    "labels_out = np.reshape(labels_out, (labels_out.shape[0],1))\n",
    "\n",
    "out = np.concatenate((labels_out, test_pred), axis=1)\n",
    "np.savetxt(\"impoutv2.csv\", out, delimiter=\",\", header=\"id,y\", comments=\"\") # NEED TO MANUALLY REMOVE # FROM HEADER (maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
