{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import r2_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. import data, normalise\n",
    "2. train different models\n",
    "    - 3 different NN structures, 5 reps each\n",
    "    - ?? GradBoostClf ?? on ROS data??\n",
    "=> ensemble \n",
    "?? 3. semi-supervised learning\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "######################################################################################################################\n",
    "### IMPORT DATA\n",
    "X_in = np.genfromtxt ('X_train.csv', delimiter=\",\")[1:,1:]\n",
    "y_in = np.genfromtxt ('y_train.csv', delimiter=\",\")[1:,1:]\n",
    "X_out = np.genfromtxt ('X_test.csv', delimiter=\",\")[1:,1:]\n",
    "\n",
    "y_in_hot = to_categorical(y_in)\n",
    "y_out = np.genfromtxt ('sample.csv', delimiter=\",\")\n",
    "\n",
    "### NORMALISE\n",
    "sts = StandardScaler()\n",
    "X_in = sts.fit_transform(X_in)\n",
    "X_out = sts.fit_transform(X_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = X_in\n",
    "y_full = y_in_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_in, X_test, y_in_hot, y_test = train_test_split(X_full, y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 1000)\n",
      "(1200, 1000)\n",
      "(3600, 3)\n",
      "(1200, 3)\n",
      "(4100, 1000)\n",
      "(4101, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_in.shape)\n",
    "print(X_test.shape)\n",
    "print(y_in_hot.shape)\n",
    "print(y_test.shape)\n",
    "print(X_out.shape)\n",
    "print(y_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback\n",
    "cb = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, \n",
    "                                   verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "### MODELS\n",
    "model_probs = np.zeros((len(X_out)   ,3), dtype=float)\n",
    "test_probs  = np.zeros((len(y_test)  ,3), dtype=float)\n",
    "train_probs = np.zeros((len(y_in_hot),3), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00007: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00009: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################################\n",
    "### FFNNs\n",
    "\n",
    "# NN FLAT\n",
    "for rep in range(5):\n",
    "    model0 = Sequential()\n",
    "    model0.add(Dense(100, activation='relu', input_dim=1000))\n",
    "    model0.add(Dropout(0.5))\n",
    "    model0.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model0.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "    model0.fit(X_in, y_in_hot, epochs=100, batch_size=128, callbacks=[cb], validation_split=0.3, \n",
    "               verbose=0, class_weight={0:1/.125, 1:1/.75, 2:1/.125}) # CAN DIRECTLY INCLUDE CLASS_WEIGHT\n",
    "\n",
    "    model_probs = model_probs+model0.predict_proba(X_out)\n",
    "    test_probs  = test_probs +model0.predict_proba(X_test)\n",
    "    train_probs = train_probs+model0.predict_proba(X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00018: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00020: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00018: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00025: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "# NN MEDIUM\n",
    "for rep in range(5):\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(40, activation='relu', input_dim=1000))\n",
    "    model1.add(Dropout(0.5))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Dense(40, activation='relu'))\n",
    "    model1.add(Dropout(0.5))\n",
    "    model1.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model1.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "    model1.fit(X_in, y_in_hot, epochs=100, batch_size=128, callbacks=[cb], validation_split=0.3, verbose=0,\n",
    "              class_weight={0:1/.125, 1:1/.75, 2:1/.125}) # CAN DIRECTLY INCLUDE CLASS_WEIGHT\n",
    "\n",
    "    model_probs = model_probs+model1.predict_proba(X_out)\n",
    "    test_probs  = test_probs +model1.predict_proba(X_test)\n",
    "    train_probs = train_probs+model1.predict_proba(X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00015: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00016: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00013: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00015: early stopping\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "# NN LARGE\n",
    "for rep in range(5):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Dense(200, activation='relu', input_dim=1000))\n",
    "    model2.add(Dropout(0.5))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Dense(200, activation='relu'))\n",
    "    model2.add(Dropout(0.5))\n",
    "    model2.add(Dense(200, activation='relu'))\n",
    "    model2.add(Dropout(0.5))\n",
    "    model2.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model2.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "    model2.fit(X_in, y_in_hot, epochs=100, batch_size=128, callbacks=[cb], validation_split=0.3, verbose=0,\n",
    "              class_weight={0:1/.125, 1:1/.75, 2:1/.125}) # CAN DIRECTLY INCLUDE CLASS_WEIGHT\n",
    "\n",
    "    model_probs = model_probs+model2.predict_proba(X_out)\n",
    "    test_probs  = test_probs +model2.predict_proba(X_test)\n",
    "    train_probs = train_probs+model2.predict_proba(X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test BMAC  = 0.6783780468394379\n",
      "train BMAC = 0.7653879014468457\n"
     ]
    }
   ],
   "source": [
    "y_out[1:,1] = np.argmax(model_probs, axis=1)\n",
    "pred_test   = np.argmax(test_probs,  axis=1)\n",
    "pred_train  = np.argmax(train_probs, axis=1)\n",
    "\n",
    "testBMAC  = balanced_accuracy_score(np.argmax(y_test,   axis=1), pred_test)\n",
    "trainBMAC = balanced_accuracy_score(np.argmax(y_in_hot, axis=1), pred_train)\n",
    "print('test BMAC  =', testBMAC)\n",
    "print('train BMAC =', trainBMAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "filename = datetime.now().strftime(\"%m.%d.%H.%M\")+\"_lucien.csv\"\n",
    "print(filename)\n",
    "np.savetxt(filename, y_out, delimiter=\",\",header=\"id,y\",  comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
