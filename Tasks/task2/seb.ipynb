{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score \n",
    "bmac = balanced_accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_file = 'X_train.csv'\n",
    "y_train_file = 'y_train.csv'\n",
    "X_test_file  = 'X_test.csv'\n",
    "\n",
    "labels_df = pd.read_csv(y_train_file)\n",
    "bare_df   = pd.read_csv(X_train_file)\n",
    "test_df   = pd.read_csv(X_test_file)\n",
    "\n",
    "bare_df.insert(0,'y',labels_df['y'])\n",
    "\n",
    "labels_df = labels_df.set_index('id')\n",
    "bare_df   = bare_df  .set_index('id')\n",
    "test_df   = test_df  .set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bare_df.shape = (4800, 1001)\n",
      "test_df.shape  = (4100, 1000)\n",
      "y distribution: \n",
      "1    3600\n",
      "2     600\n",
      "0     600\n",
      "Name: y, dtype: int64\n",
      "We are told that \"Test set has the same class imbalance as the training set.\"\n"
     ]
    }
   ],
   "source": [
    "print('bare_df.shape =', bare_df.shape)\n",
    "print('test_df.shape  =', test_df.shape)\n",
    "print('y distribution: ')\n",
    "print(bare_df['y'].value_counts())\n",
    "print('We are told that \\\"Test set has the same class imbalance as the training set.\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_normalise(df):\n",
    "    return (df-df.mean())/df.std()\n",
    "\n",
    "def min_max_normalise(df):\n",
    "    return (2*df-df.min()-df.max())/(df.max()-df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oh(y):\n",
    "    y0 = y == 0\n",
    "    y1 = y == 1\n",
    "    y2 = y == 2\n",
    "    return np.stack((y0,y1,y2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "do the oversampling after train/test split",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9759664c41e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'do the oversampling after train/test split'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Class count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcount_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbare_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Divide by class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: do the oversampling after train/test split"
     ]
    }
   ],
   "source": [
    "raise Exception('do the oversampling after train/test split')\n",
    "# Class count\n",
    "count_1, count_2, count_0 = bare_df['y'].value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_0 = bare_df[bare_df['y'] == 0]\n",
    "df_1 = bare_df[bare_df['y'] == 1]\n",
    "df_2 = bare_df[bare_df['y'] == 2]\n",
    "# Let's try balancing out the classes with over-sampling\n",
    "df_0_over = df_0.sample(count_1, replace=True)\n",
    "df_2_over = df_2.sample(count_1, replace=True)\n",
    "over_df = pd.concat([df_0_over, df_1, df_2_over], axis=0)\n",
    "# I expect this to be bigger, count1*3 = 10800\n",
    "over_df.shape\n",
    "\n",
    "# so, BMAC didn't change, but we also made a mistake\n",
    "# we should be oversampling on the test set too\n",
    "# what to expect? if we get better will BMAC reward us for well handled class imbalance?\n",
    "# Does NB classifier even care about sample repetitions? \n",
    "# I think yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing and preparing feature and label matrices\n",
    "nrm_df = mean_std_normalise(bare_df.drop(columns='y'))\n",
    "nrm_df['y'] = bare_df['y']\n",
    "\n",
    "# dividing X, y into train and test data \n",
    "df_train, df_test = train_test_split(nrm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 1001)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Oversampling the training set only\n",
    "# Class count\n",
    "count_1, count_2, count_0 = df_train['y'].value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_0 = df_train[df_train['y'] == 0]\n",
    "df_1 = df_train[df_train['y'] == 1]\n",
    "df_2 = df_train[df_train['y'] == 2]\n",
    "# Let's try balancing out the classes with over-sampling\n",
    "df_0_over = df_0.sample(count_1, replace=True)\n",
    "df_2_over = df_2.sample(count_1, replace=True)\n",
    "over_df = pd.concat([df_0_over, df_1, df_2_over], axis=0)\n",
    "# I expect this to be bigger, count1*3 = 10800\n",
    "over_df.shape\n",
    "\n",
    "# so, BMAC didn't change, but we also made a mistake\n",
    "# we should be oversampling on the test set too\n",
    "# what to expect? if we get better will BMAC reward us for well handled class imbalance?\n",
    "# Does NB classifier even care about sample repetitions? \n",
    "# I think yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape = (3600, 1000) to (3600, 3)\n",
      "test shape  = (1200, 1000) to (1200, 3)\n",
      "\n",
      "n0test = 13.2%\n",
      "n1test = 74.3%\n",
      "n2test = 12.4%\n",
      "\n",
      "n0train = 12.2%\n",
      "n1train = 75.2%\n",
      "n2train = 12.5%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ONE HOTS\n",
    "X_train = df_train.drop(columns='y').values\n",
    "y_train = oh(df_train['y'].values)\n",
    "n_train = len(y_train)\n",
    "\n",
    "X_test = df_test.drop(columns='y').values\n",
    "y_test = oh(df_test['y'].values)\n",
    "n_test = len(y_test)\n",
    "print(\"train shape =\", np.shape(X_train),'to',np.shape(y_train))\n",
    "print(\"test shape  =\", np.shape(X_test), 'to',np.shape(y_test))\n",
    "print()\n",
    "print('n0test = %.1f%%'%(100/n_test*np.sum(y_test[:,0])))\n",
    "print('n1test = %.1f%%'%(100/n_test*np.sum(y_test[:,1])))\n",
    "print('n2test = %.1f%%'%(100/n_test*np.sum(y_test[:,2])))\n",
    "print()\n",
    "print('n0train = %.1f%%'%(100/n_train*np.sum(y_train[:,0])))\n",
    "print('n1train = %.1f%%'%(100/n_train*np.sum(y_train[:,1])))\n",
    "print('n2train = %.1f%%'%(100/n_train*np.sum(y_train[:,2])))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape =  (4800, 1000)\n",
      "test shape  =  (1200, 1000)\n",
      "\n",
      "n0test = 13.2%\n",
      "n1test = 74.3%\n",
      "n2test = 12.4%\n",
      "\n",
      "n0train = 12.5%\n",
      "n1train = 75.0%\n",
      "n2train = 12.5%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = nrm_df.drop(columns='y').values\n",
    "y_train = nrm_df['y'].values\n",
    "n_train = len(y_train)\n",
    "\n",
    "X_test = df_test.drop(columns='y').values\n",
    "y_test = df_test['y'].values\n",
    "n_test = len(y_test)\n",
    "print(\"train shape = \", np.shape(X_train))\n",
    "print(\"test shape  = \", np.shape(X_test))\n",
    "print()\n",
    "print('n0test = %.1f%%'%(100/n_test*np.sum((y_test == 0))))\n",
    "print('n1test = %.1f%%'%(100/n_test*np.sum((y_test == 1))))\n",
    "print('n2test = %.1f%%'%(100/n_test*np.sum((y_test == 2))))\n",
    "print()\n",
    "print('n0train = %.1f%%'%(100/n_train*np.sum((y_train == 0))))\n",
    "print('n1train = %.1f%%'%(100/n_train*np.sum((y_train == 1))))\n",
    "print('n2train = %.1f%%'%(100/n_train*np.sum((y_train == 2))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'class_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8cc757611d72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# training a DecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdtree_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpresort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.125\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.125\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'class_weights'"
     ]
    }
   ],
   "source": [
    "# training a DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(presort = True, max_depth = 8, class_weights=(0.125,0.75,0.125)).fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a linear SVM classifier \n",
    "from sklearn.svm import SVC \n",
    "svm_model_linear = SVC(gamma='scale',class_weight={0:1/.125, 1:1/.75, 2:1/.125}, probability = True, kernel = 'rbf', C = 1).fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a KNN classifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a Naive Bayes classifier \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB().fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtree_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-b985ac6e0077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdtree_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtree_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdtree_train_pred\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdtree_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mBMAC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtree_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtsBMAC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtree_train_pred\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BMAC ='\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBMAC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dtree_model' is not defined"
     ]
    }
   ],
   "source": [
    "dtree_predictions = dtree_model.predict(X_test) \n",
    "dtree_train_pred  = dtree_model.predict(X_train)\n",
    "BMAC = balanced_accuracy_score(y_test, dtree_predictions)\n",
    "tsBMAC = balanced_accuracy_score(y_train, dtree_train_pred )\n",
    "print('BMAC =',BMAC)\n",
    "print('trainset BMAC =', tsBMAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMAC = 0.9801943198804185\n",
      "trainset BMAC = 0.9798148148148149\n"
     ]
    }
   ],
   "source": [
    "svm_predictions = svm_model_linear.predict(X_test)\n",
    "svm_train_pred  = svm_model_linear.predict(X_train)\n",
    "BMAC = balanced_accuracy_score(y_test, svm_predictions)\n",
    "tsBMAC = balanced_accuracy_score(y_train, svm_train_pred)\n",
    "print('BMAC =',BMAC)\n",
    "print('trainset BMAC =', tsBMAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMAC = 0.7065175567113098\n",
      "trainset BMAC = 0.9743873907154291\n"
     ]
    }
   ],
   "source": [
    "svm_predictions = svm_model_linear.predict(X_test)\n",
    "svm_train_pred  = svm_model_linear.predict(X_train)\n",
    "BMAC = balanced_accuracy_score(y_test, svm_predictions)\n",
    "tsBMAC = balanced_accuracy_score(y_train, svm_train_pred)\n",
    "print('BMAC =',BMAC)\n",
    "print('trainset BMAC =', tsBMAC)\n",
    "# SVC with RBF kernel, oversampled, prob = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMAC = 0.5670984409081278\n",
      "trainset BMAC = 0.705071269823505\n"
     ]
    }
   ],
   "source": [
    "svm_predictions = svm_model_linear.predict(X_test)\n",
    "svm_train_pred  = svm_model_linear.predict(X_train)\n",
    "BMAC = balanced_accuracy_score(y_test, svm_predictions)\n",
    "tsBMAC = balanced_accuracy_score(y_train, svm_train_pred)\n",
    "print('BMAC =',BMAC)\n",
    "print('trainset BMAC =', tsBMAC)\n",
    "# SVC with RBF kernel, imbalanced, prob = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_predictions = knn.predict(X_test) \n",
    "knn_train_pred  = knn.predict(X_train) \n",
    "BMAC = balanced_accuracy_score(y_test, knn_predictions)\n",
    "tsBMAC = balanced_accuracy_score(y_train, knn_train_pred)\n",
    "print('BMAC =',BMAC)\n",
    "print('trainset BMAC =', tsBMAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_predictions = gnb.predict(X_test) \n",
    "gnb_train_pred  = gnb.predict(X_train)\n",
    "BMAC = balanced_accuracy_score(y_test, gnb_predictions)\n",
    "tsBMAC = balanced_accuracy_score(y_train, gnb_train_pred)\n",
    "print('BMAC =',BMAC)\n",
    "print('trainset BMAC =', tsBMAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_proba       = dtree_model.predict_proba(X_test)\n",
    "svm_proba         = svm_model_linear.predict_proba(X_test)\n",
    "knn_proba         = knn.predict_proba(X_test)\n",
    "gnb_proba         = gnb.predict_proba(X_test)\n",
    "dtree_train_proba = dtree_model.predict_proba(X_train)\n",
    "svm_train_proba   = svm_model_linear.predict_proba(X_train)\n",
    "knn_train_proba   = knn.predict_proba(X_train)\n",
    "gnb_train_proba   = gnb.predict_proba(X_train)\n",
    "\n",
    "\n",
    "ensemble_pred = dtree_proba      +svm_proba      +knn_proba      +gnb_proba\n",
    "ensemble_train_pred = dtree_train_proba+svm_train_proba+knn_train_proba+gnb_train_proba\n",
    "print(bmac(oh(y_test,ensemble_pred)))\n",
    "print(bmac(oh(y_train,ensemble_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histograms show that NBClassifier is always very confident\n",
    "proba = gnb.predict_proba(X_train)\n",
    "y_test_oh = np.zeros((y_test.size, y_test.max()+1))\n",
    "y_test_oh[np.arange(y_test.size),y_test] = 1\n",
    "y_train_oh = np.zeros((y_train.size, y_train.max()+1))\n",
    "y_train_oh[np.arange(y_train.size),y_train] = 1\n",
    "print(proba - y_train_oh)\n",
    "\n",
    "#plt.hist(proba-y_test_oh)\n",
    "\n",
    "\n",
    "#plt.hist(y_train)\n",
    "gnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_graded = mean_std_normalise(test_df).values\n",
    "y_graded = svm_model_linear.predict(X_graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.12.00.48_seb_vanilla_svm_rbf.csv\n"
     ]
    }
   ],
   "source": [
    "y_out_template = np.genfromtxt ('sample.csv', delimiter=\",\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.12.01.04_seb_vanilla_svm_rbf.csv\n"
     ]
    }
   ],
   "source": [
    "filename = datetime.now().strftime(\"%m.%d.%H.%M\")+\"_seb_vanilla_svm_rbf.csv\"\n",
    "print(filename)\n",
    "y_out=y_out_template\n",
    "y_out[:,1] = y_graded\n",
    "np.savetxt(filename, y_out, delimiter=\",\",header=\"id,y\",  comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ignore BELOW here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (7,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.plot.scatter(x='x0', y='x1', c='y',colormap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, so we have tons of dimensions and I want to get the useful ones.\n",
    "\n",
    "PCA seems like a good idea, but remember that you have imbalanced classes!\n",
    "Intuitively for me imbalanced classes will also imbalance PCA.\n",
    "Does PCA make sense for classification? YES, but not for multiclass, as there is no induced ordering.\n",
    "\n",
    "We have to take a 1-vs-X approach ALREADY...\n",
    "\n",
    "To make things simple for my self I will start with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA 1 vs 1 (between the two balanced classes, y =  0 and y = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_02 = train_df[train_df['y'] != 1]\n",
    "print(full_02.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_normalise(df):\n",
    "    return (df-df.mean())/df.std()\n",
    "\n",
    "def min_max_normalise(df):\n",
    "    return (2*df-df.min()-df.max())/(df.max()-df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_02 = mean_std_normalise(full_02)\n",
    "full_02['y'] = min_max_normalise(full_02['y'])\n",
    "full_02.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_02.drop(columns = 'y').values\n",
    "y = full_02['y'].values\n",
    "print('shape(X) = ', np.shape(X))\n",
    "print('shape(y) = ', np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA seems like a good idea, but remember that you have imbalanced classes!\n",
    "# Intuitively for me imbalanced classes will also imbalance PCA.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "pca.fit(X)\n",
    "princX = pca.transform(X)\n",
    "plt.scatter(princX[:, 0], princX[:, 1], c=y, cmap=plt.cm.nipy_spectral,\n",
    "           edgecolor='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "princX = CCA(n_components=2).fit(X, y).transform(X)\n",
    "print(princX)\n",
    "plt.scatter(princX[:, 0], princX[:, 1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from fancyimpute import simple_fill\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. normalise\n",
    "\n",
    "#X_in = X_imp;\n",
    "#X_out = Xt_imp;\n",
    "X_tot = X_imp\n",
    "#X_tot = np.concatenate((X_in, X_out), axis=0)\n",
    "scaler = StandardScaler()\n",
    "X_tot = scaler.fit_transform(X_tot)\n",
    "X_in = X_tot[:X_in.shape[0],:]\n",
    "X_out = X_tot[X_in.shape[0]:,:]\n",
    "print(X_in.shape)\n",
    "print(X_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
